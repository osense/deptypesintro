\documentclass[12pt]{article}
\usepackage[mathletters]{ucs}
\usepackage[utf8x]{inputenc}
\usepackage[english]{babel}
\usepackage{proof}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{latexsym}
\usepackage{tikz-cd}

\usepackage{graphicx}
\graphicspath{{images/}}

\usepackage{verbatim}
\newenvironment{code}{\verbatim}{\endverbatim}

\usepackage[backend=bibtex]{biblatex}
\bibliography{citations}

\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\newcommand{ℕ}{\mathbb{N}}
\newcommand{\true}{\enskip\mathrm{true}}
\newcommand{\term}{\enskip\mathrm{term}}

\title{Dependent types}
\author{Adam Krupicka\\
        Faculty of Informatics\\
        Masaryk University, Brno
}
\date{23.5.2016}


\begin{document}
\maketitle

\begin{abstract}
This short essay aims to give an intuitive overview of Dependent types, their correspondence with First-order predicate logic, and their practical uses.
\end{abstract} 

\section{Introduction}
In sections – through –, some prior knowledge of the Curry-Howard isomorphism and related topics is assumed. An outline can be found in e.g.~\cite{mcadams2013tutorial}.

\newpage

\section{Dependent types}
A dependent type is a type which depends on other values. For example, the type of vectors of natural numbers of length $n$ depends on the concrete value of $n$.
\subsection{λΠ}
The simplest system of dependent types, usually referred to as λΠ, is outlined below. There are two basic building blocks used to construct dependent types.

\paragraph{Dependent functions}
A dependent function is a function from some value $a$ of type $A$ to the type $B(a)$. Formally, this is written as $Π(a:A).B(a)$. For example, $Π(n:ℕ).Vecℕ(n)$ would be a function from some $n:ℕ$ to the type of vectors of natural numbers of length $n$, where we write $Vecℕ(n)$ for $n$-tuples of natural numbers. If $B(a)$ is a constant function to some type $C$, then we get a regular function type $A → C$, familiar from the Simply typed λ calculus. For example, $Π(n:ℕ).ℕ $ is equivalent to $ℕ → ℕ$.

\paragraph{Dependent pairs}
A dependent pair is a pair where the value $a:A$ of the first element determines the type of the second element $B(a)$. This is written as $Σ(a:A).B(a)$. If $B(a)$ is a constant function to some type $C$, then we get a regular non-dependent pair of the type $A × C$.

\paragraph{}
This is the basic outline of the simplest system of dependent types, usually referred to as $λΠ$. The operators $''Π''$ and $''Σ''$ are allowed to range only over values, as was the case in e.g.\ the type of vectors of some length $n$. We saw that already this system subsumed the type operators $''→''$ and $''×''$ from $λ→$.

\subsection{λΠ2}
When we further extend the range of the $''Π''$ and $''Σ''$ operators to allow ranging over types, we immediately obtain a richer system. This system now subsumes the $''Λ''$ operator known from the Polymorphic λ calculus. For example, we can now generalize our example of vectors from the previous section to all types of elements, rather than just one fixed type:
$$ Π(A:Ω).Π(n:ℕ).Vec(A, n) $$
Here, $Ω$ stands for the type of all atomic types in our system.

When we further allow the binders to range over higher types, we obtain the system $λΠω$. This system, with some extensions, serves as the basis for the proof assistant Coq~\cite{bertot2013interactive}. This hierarchy is outlined in Figure~\ref{lc}.

\begin{figure}
    \[
        \begin{tikzcd}[row sep=large]
            & λω \ar{rr} \ar[from=dd] & & λΠω \\
            λ2 \ar{ur} \ar[rr, crossing over] & & λΠ2 \ar[ur, very thick] \\
            & λ\underline{ω} \ar{rr} & & λΠ\underline{ω} \ar{uu} \\
            λ→ \ar[rr, very thick] \ar{uu} \ar{ur} & & λΠ \ar[uu, crossing over, very thick] \ar{ur} \\
        \end{tikzcd}
    \]
    \caption{The Lambda cube. Path we have followed in thick.}
\label{lc}
\end{figure}

\section{The Curry-Howard correspondence}


\section{Dependent types in practice}
In this section, I have included a practical demonstration of dependent types. We will use a proof assistant/programming language based on intuitionistic type theory called Agda~\cite{norell2007towards}. Agda is even more expressive than λΠω, as it constitutes a so-called Pure Type System. Pure Type Systems are a generalization over the systems of the λ cube from Figure~\ref{lc}~\cite{sorensen2006lectures}.

\subsection{Vectors}
We have already seen that dependent types make it possible to define vectors of fixed lenght. To encode vectors in Agda, we will first have to define natural numbers.
\begin{verbatim}
    data ℕ : Set where
      zero : ℕ 
      succ : ℕ → ℕ
\end{verbatim}
This is a data type declaration with two constructors. The first, nullary constructor simply represents zero. The second, unary constructor represent the successor function. For example to encode the number 4, we would write \verb|succ(succ(succ(succ(zero))))|. The type \verb|ℕ| is itself of the type \verb|Set|.

Equipped with Peano numbers, we can now define the type of vectors.
\begin{verbatim}
    data Vec (A : Set) : ℕ → Set where
      []   : Vec A zero
      _::_ : {n : ℕ} → A →  Vec A n → Vec A (succ n)
\end{verbatim}
A vector is parametrized by the type of it's elements \verb|A| and is itself of the type \verb|ℕ → Set|. Again we have two constructors; the first constructor simply represents an empty vector. The second constructor prepends a value to the head of a vector. For example, the vector $[1, 2, 3]$ would be represented as \verb|1 :: (2 :: (3 :: []))|.

Compared to regular lists of any length, the immediate improvement is that now we can define our \verb|head| and \verb|tail| functions in a manner which enforces these to be only applied to non-empty vectors.
\begin{verbatim}
    head : {n : ℕ} → {A : Set} → Vec A (succ n) → A
    head (x :: _) = x

    tail : {n : ℕ} → {A : Set} → Vec A (succ n) → Vec A n
    tail (_ :: xs) = xs
\end{verbatim}
Note that the length of the input vector is \verb|succ n|. This enforces the programmer to always pass to the function an input vector of length at least $1$, otherwise the type checker will not successfully verify the code.

\paragraph{}
We can define addition and multiplication on Peano numbers recursively.
\begin{verbatim}
    _+_ : ℕ → ℕ → ℕ
    zero + b = b
    (succ a) + b = succ (a + b)

    _*_ : ℕ → ℕ → ℕ
    zero * b = zero
    (succ a) * b = b + (a * b)
\end{verbatim}
With these operations, we can now express more advanced functions on vectors.
\begin{verbatim}
    append : {n m : ℕ} → {A : Set} → Vec A n → Vec A m → Vec A (n + m)
    append [] ys = ys
    append (x :: xs) ys = x :: append xs ys

    concat : {n m : ℕ} → {A : Set} → Vec (Vec A m) n → Vec A (n * m)
    concat [] = []
    concat (xs :: xss) = append xs (concat xss)
\end{verbatim}
\verb|append| simply appends two vectors, whereas \verb|concat| concatenates a vector of vectors into a single vector. Note that each vector is of the same, fixed length $m$ inside the outer vector of length $n$. This is a natural way to encode matrices. As an example of a matrix function, we might want to extract the diagonal of a matrix. However, the matrix must be square! This is easy to express on the type level.
\begin{verbatim}
    map : {n : ℕ} → {A B : Set} → Vec (A → B) n → Vec A n → Vec B n
    map [] [] = []
    map (f :: fs) (x :: xs) = (f x) :: (map fs xs)

    diagonal : {n : ℕ} → {A : Set} → Vec (Vec A n) n → Vec A n
    diagonal [] = []
    diagonal (xs :: xss) = head xs :: diagonal (map tail xss)
\end{verbatim}

\subsection{Natural deduction}
In the previous subsection, we have seen a few examples of how dependent types can help us be more expressive about the types of our computations. In this subsection, we will look at another application of dependent types — theorem proving. Following the Curry–Howard Isomorphism, this should come as no surprise. Dependent types are very expressive, which is why they are fitting for the task. Now, let us prove some basic properties of Propositional logic.

\paragraph{Conjunction}
Our system will closely model the rules of Natural Deduction. We will define introduction as a data type constructor, and eliminations as functions.
\begin{verbatim}
    data _∧_ (P : Set) (Q : Set) : Set where
      _,_ : P → Q → (P ∧ Q)

    ∧-elim₁ : {P Q : Set} → (P ∧ Q) → P
    ∧-elim₁ (p , q) = p

    ∧-elim₂ : {P Q : Set} → (P ∧ Q) → Q
    ∧-elim₂ (p , q) = q
\end{verbatim}
We can prove some basic properties of conjunction, e.g.~commutativity. We will implement a function, which — with the help of pattern matching — deconstructs the proof of $p ∧ q$ into proofs of $p$ and $q$, and then arranges them back into a conjunction in the required order. This corresponds with the standard understanding of implication in intuitionistic logic.
\begin{verbatim}
    ∧-comm' : {P Q : Set} → (P ∧ Q) → (Q ∧ P)
    ∧-comm' (p , q) = (q , p)
\end{verbatim}
Note that, strictly speaking, we have only proved one direction of the equivalence. In this simple case this makes no difference, as both directions are analogous, however in more complex proofs we would wish to prove both directions. We will therefore define equivalence on a meta-level (not inside our Natural Deduction system) and restate the commutativity proof.
\begin{verbatim}
    _⇔_ : (P : Set) → (Q : Set) → Set
    p ⇔ q = (p → q) ∧ (q → p)

    ∧-comm : {P Q : Set} → (P ∧ Q) ⇔ (Q ∧ P)
    ∧-comm = (∧-comm' , ∧-comm')
\end{verbatim}
The commutativity proof now reflects our intuitive understanding of it. Both implications are analogous, therefore we can simply reuse our original proof in both directions.

Associativity can be proved in a very similar fashion. We can view the first two functions as lemmas, and the third function as a corrolary.
\begin{verbatim}
    ∧-assoc¹ : {P Q R : Set} → (P ∧ (Q ∧ R)) → ((P ∧ Q) ∧ R)
    ∧-assoc¹ (p , (q , r)) = ((p , q) , r)

    ∧-assoc² : {P Q R : Set} → ((P ∧ Q) ∧ R) → (P ∧ (Q ∧ R))
    ∧-assoc² ((p , q) , r) = (p , (q , r))

    ∧-assoc : {P Q R : Set} → (P ∧ (Q ∧ R)) ⇔ ((P ∧ Q) ∧ R)
    ∧-assoc = (∧-assoc¹ , ∧-assoc²)
\end{verbatim}

\paragraph{Disjunction}
We will now define disjunction. As in Natural Deduction, we will employ two introductions and one elimination.
\begin{verbatim}
    data _∨_ (P : Set) (Q : Set) : Set where
      left : P → (P ∨ Q)
      right : Q → (P ∨ Q)

    ∨-elim : {P Q R : Set} → (P → R) → (Q → R) → (P ∨ Q) → R
    ∨-elim f _ (left p) = f p
    ∨-elim _ g (right q) = g q
\end{verbatim}
Once again, our functions closely model the rules of Natural Deduction. We will not concern ourselves with the proofs of commutativity and associativity, as they are similar to those of conjunction.

Instead, we will present proofs of theorems of both our logical connectives combined\footnote{That is, identities valid in the variety of Boolean algebras.}. A proof of absorption can be formalized thusly:
\begin{verbatim}
    abs₁ : {P Q : Set} → (P ∧ (P ∨ Q)) ⇔ P
    abs₁ = (∧-elim₁ , λ p → (p , left p))

    abs₂ : {P Q : Set} → (P ∨ (P ∧ Q)) ⇔ P
    abs₂ = (∨-elim (λ x → x) ∧-elim₁ , left)
\end{verbatim}
One direction of the theorems is always trivial; the other has to be constructed appropriately. For this, we utilize a lambda expression in the first theorem, and we have to eliminate a disjunction in the second theorem — in this case, the identity function comes in handy.

Finally, we shall prove the distributive laws. These are a bit more wordy, however they follow the same principles of simply reorganizing the formulas as we require.
\begin{verbatim}
    distrib₁¹ : {P Q R : Set} → (P ∧ (Q ∨ R)) → ((P ∧ Q) ∨ (P ∧ R))
    distrib₁¹ (p , (left q)) = left (p , q)
    distrib₁¹ (p , (right r)) = right (p , r)

    distrib₁² : {P Q R : Set} → ((P ∧ Q) ∨ (P ∧ R)) → (P ∧ (Q ∨ R))
    distrib₁² (left (p , q)) = p , (left q)
    distrib₁² (right (p , r)) = p , (right r)

    distrib₁ : {P Q R : Set} → (P ∧ (Q ∨ R)) ⇔ ((P ∧ Q) ∨ (P ∧ R))
    distrib₁ = (distrib₁¹ , distrib₁²)


    distrib₂¹ : {P Q R : Set} → (P ∨ (Q ∧ R)) → ((P ∨ Q) ∧ (P ∨ R))
    distrib₂¹ (left p) = (left p , left p)
    distrib₂¹ (right (q , r)) = (right q , right r)

    distrib₂² : {P Q R : Set} → ((P ∨ Q) ∧ (P ∨ R)) → (P ∨ (Q ∧ R))
    distrib₂² ((left p) , _) = left p
    distrib₂² (_ , (left p)) = left p
    distrib₂² ((right q) , (right r)) = right (q , r)

    distrib₂ : {P Q R : Set} → (P ∨ (Q ∧ R)) ⇔ ((P ∨ Q) ∧ (P ∨ R))
    distrib₂ = (distrib₂¹ , distrib₂²)
\end{verbatim}
Note that at several occasions we have avoided having to use disjunction elimination, and instead utilized pattern matching to handle the distinct possibilities of deconstructing a proof of $p ∨ q$ and finding within a proof of either $p$, or $q$.

\section{A note on decidability}

\printbibliography{}
\end{document}

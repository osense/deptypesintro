\documentclass[12pt]{article}
\usepackage[mathletters]{ucs}
\usepackage[utf8x]{inputenc}
\usepackage[english]{babel}
\usepackage{proof}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{latexsym}
\usepackage{tikz-cd}

\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\newcommand{ℕ}{\mathbb{N}}
\newcommand{\true}{\enskip\mathrm{true}}
\newcommand{\term}{\enskip\mathrm{term}}

\title{Dependent types}
\author{Adam Krupicka\\
        Faculty of Informatics\\
        Masaryk University, Brno
}
\date{23.5.2016}


\begin{document}
\maketitle

\begin{abstract}
ABSTRACT
\end{abstract}


\section{Introduction}
…


\section{Definitions}

To say that some variable is \textbf{free} in a type means that it does not occur anywhere in it (e.g.\ $A$ is free in $B$ or $B → B$, but not in $A → B → B$).

\textbf{$\mathcal{L} (\mathcal{M})$} denotes the language of some calculus \mathcal{M}, that is, all the terms that can be constructed from some fixed starting set of variables.

\section{First-order predicate logic}


\subsection{Natural deduction}
We will consider a fragment consisting only of implication and the quantifiers. Why this is sufficient will become clear in the next section.
\paragraph{Hypothesis}
\[A\]
\paragraph{Implication}
$$
\infer[\mathrm{⇒I^u}]{A ⇒ B \true}{\infer*{B \true}{\infer[u]{A \true}}}
\qquad
\infer[\mathrm{⇒E}]{B \true}{A \true & A ⇒ B \true}
$$
The introduction rule on the left states that assuming some initial hypothesis $A$, if we then proceed to show $B$, then $A ⇒ B$ holds; however we must remember to discharge our initial hypothesis of $A$. It can be thought of as taking the entire derivation tree of $B$ from the hypothetical $A$ and stating it more succinctly as $A ⇒ B$.

The elimination rule on the right should be obvious.
\paragraph{Universal quantification}
$$
\infer[\mathrm{∀I^u}]{∀x.A \true}{\infer*{A[x:=t] \true}{\infer[u]{t \term}}}
\qquad
\infer[\mathrm{∀E}]{A[x:=t] \true}{∀x.A \true & t \term}
$$
The introduction rule is easier to read bottom to top: if we wish to conclude $∀x.A$, then we are required to show that if we replace every instance of $x$ in $A$ with some arbitrary term $t$, $A$ still holds. The term $t$ can be thought of as a variable, because we are not allowed to assume anything about it — it is just some $t$.

The rule on the right is, again, rather obvious — it allows us to specialize a universally qualified formula back into some term.
\paragraph{Existential quantification}
$$
\infer[\mathrm{∃I^u}]{∃x.A[t:=x] \true}{A \true}
\qquad
\infer[\mathrm{∃E^{u,v}}]{B \true}{∃x.A \true & \infer*{B \true}{\qquad \infer[u]{t \term} & \infer[v]{A[x:=t] \true}}}
$$
Here, the introduction rule states that if we have a proposition $A$ containing some term $t$ which happens to be true, then we can abstract away from the specific $t$ and simply conclude the existence of some $x$ where $A[t:=x]$ is true.

The elimination rule says that in order to prove anything from a proof of $∃x.A$, we must first find some term $t$, which can be substituted into $A$ instead of the variable $x$. Then, if we can prove some proposition $B$ from that $A[x:=t]$, we may conclude $B$, eliminating the existential quantifier.


\section{Dependent types}
A dependent type is a type which depends on other values. For example, the type of vectors of natural numbers of length $n$ depends on the concrete value of $n$. There are two basic building blocks used to construct dependent types.

\paragraph{Dependent functions}
A dependent function is a function from some value $a$ of type $A$ to the type $B(a)$. Formally, this is written as $∏(a:A).B(a)$. For example, $∏(n:ℕ).Vecℕ(n)$ would be a function from some $n:ℕ$ to the type of vectors of natural numbers of length $n$, where we write $Vecℕ(n)$ for $n$-tuples of natural numbers. If $B(a)$ is a constant function to some type $C$, then we get a regular function type $A → C$, familiar from the Simply typed λ calculus. For example, $∏(n:ℕ).ℕ $ is equivalent to $ℕ → ℕ$.

\paragraph{Dependent pairs}
A dependent pair is a pair where the value $a:A$ of the first element determines the type of the second element $B(a)$. This is written as $∑(a:A).B(a)$. If $B(a)$ is a constant function to some type $C$, then we get a regular non-dependent pair of the type $A×C$.

\subsection{Systems of the Lambda cube}
I have outlined the basic system of dependent types, usually refered to as $λΠ$, in the previous section. In $λΠ$, dependent functions and pairs are allowed to range only over values, as was the case in e.g.\ the type of vectors of some length $n$. We saw that already this system subsumed the type operators $→$ and $×$ from $λ→$. When we further extend the range of the binders $∏$ and $∑$ to allow ranging over types, we immediately obtain a richer system. This system, $λΠ2$, now subsumes the polymorphic $Λ$ operator known from the Polymorphic λ calculus. When we further allow the binders to range over higher types, we obtain the system $λΠω$. This system is the basis of proof assistant Coq.

This hierarchy is outlined in Figure~\ref{lc}.

\begin{figure}
    \[
        \begin{tikzcd}[row sep=large]
            & λω \ar{rr} \ar[from=dd] & & λΠ \\
            λ2 \ar{ur} \ar[rr, crossing over] & & λΠ2 \ar[ur, very thick] \\
            & λω \ar{rr} & & λΠω \ar{uu} \\
            λ→ \ar[rr, very thick] \ar{uu} \ar{ur} & & λΠ \ar[uu, crossing over, very thick] \ar{ur} \\
        \end{tikzcd}
    \]
    \caption{The Lambda cube. Path we have followed in thick.}
    \label{lc}
\end{figure}

\section{The Curry-Howard correspondence}


\section{Dependent types in practice}


\end{document}
